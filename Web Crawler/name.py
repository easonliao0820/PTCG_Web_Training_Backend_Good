import requests
from bs4 import BeautifulSoup
import json
import os
import re

BASE_URL = "https://asia.pokemon-card.com"

# ---- æ ¼å¼åŒ–å¡åï¼šæ‹†å‡º <é˜¿éŸ¿çš„>å‡±ç¾…æ–¯ -> é˜¿éŸ¿çš„å‡±ç¾…æ–¯ ----
def extract_card_name(h1_tag):
    if h1_tag is None:
        return ""

    # æŠŠ evolveMarker ç§»é™¤
    em = h1_tag.find("span", class_="evolveMarker")
    if em:
        em.extract()

    raw = "".join(h1_tag.stripped_strings)

    # ä¿®æ­£ HTML ç¬¦è™Ÿ like "&lt;é˜¿éŸ¿çš„&gt;" -> "<é˜¿éŸ¿çš„>"
    raw = raw.replace("&lt;", "<").replace("&gt;", ">")

    # æŠŠ <é˜¿éŸ¿çš„>å‡±ç¾…æ–¯ -> é˜¿éŸ¿çš„å‡±ç¾…æ–¯
    raw = re.sub(r"<(.*?)>", r"\1", raw)

    return raw.strip()


# ---- æ ¼å¼åŒ–ç·¨è™Ÿï¼š001/193 -> 001 ----
def extract_number(num_tag):
    if num_tag is None:
        return ""

    txt = num_tag.text.strip()
    match = re.match(r"(\d+)", txt)
    return match.group(1).zfill(3) if match else ""

# ---- æŠ“å‡ºè¡€é‡ ----
def extract_hp(hp_tag):
    if hp_tag is None:
        return ""
    
    txt = hp_tag.text.strip()
    return txt

# ---- æŠ“å‡ºéšæ®µ ----
def extract_stage(stage_tag):
    if stage_tag is None:
        return ""
    
    txt = stage_tag.text.strip()
    return txt

# ---- æŠ“å‡ºå¡ç‰Œæè¿° ----
def extract_info(info_tag):
    if info_tag is None:
        return ""
    
    txt = info_tag.text.strip()
    return txt

# ---- å¾å±¬æ€§åœ–ç¤ºURLå–å‡ºèƒ½é‡å±¬æ€§ ----
def extract_energy(energy_tag):
    if energy_tag is None:
        return ""

    src = energy_tag.get("src", "")
    filename = src.split("/")[-1]  

    energy_name = filename.split(".")[0]  

    return energy_name

# ---- æŠ“å¡åœ–çš„url ----
def get_local_image_url(expansion, number):
    folder = "pokemon_images"
    filename = f"{expansion} {number}.jpg"
    path = os.path.join(folder, filename)

    if os.path.exists(path):
        return path.replace("\\", "/")

    return ""

# æŠ“åˆ—è¡¨é æ‰€æœ‰å¡ ID
def get_card_ids(list_url):
    res = requests.get(list_url)
    soup = BeautifulSoup(res.text, "html.parser")
    links = soup.select("a[href*='/card-search/detail/']")
    ids = []

    for link in links:
        href = link["href"]
        card_id = href.split("/")[-2]
        ids.append(card_id)

    return ids


# æŠ“è©³ç´°é è³‡æ–™
def get_card_detail(card_id, expansion):
    url = f"{BASE_URL}/tw/card-search/detail/{card_id}/"
    res = requests.get(url)
    soup = BeautifulSoup(res.text, "html.parser")

    h1_tag = soup.select_one("h1.pageHeader.cardDetail")
    number_tag = soup.select_one("span.collectorNumber")
    hp_tag = soup.select_one("span.number")
    energy_tag = soup.select_one("p.mainInfomation img")
    stage_tag = soup.select_one("span.evolveMarker")
    info_tag = soup.select_one("p.discription")

    name = extract_card_name(h1_tag)
    number = extract_number(number_tag)
    hp = extract_hp(hp_tag)
    energy = extract_energy(energy_tag)
    stage = extract_stage(stage_tag)
    info = extract_info(info_tag)
    image_url = get_local_image_url(expansion, number)

    return {
        "card_id": f"{expansion}_{number}",
        "name": name,
        "hp": hp,
        "stage": stage,
        "image_url": f"/assets/cards/{expansion} {number}.png",
        "info": info,
        "energy_en": energy,
        "collection_code": expansion,
        "specal_card_type": "",
        "rarity_id": ""
    }


#å„²å­˜æˆ JSON
def save_to_json(cards, filename="cards.json"):
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(cards, f, ensure_ascii=False, indent=4)

    print(f"å·²è¼¸å‡ºJSONæª”ï¼š{filename}")


# ------------------ ä¸»ç¨‹å¼ ---------------------
if __name__ == "__main__":
    expansion = "M2"
    page = 1
    cards = []

    while True:
        list_url = f"https://asia.pokemon-card.com/tw/card-search/list/?pageNo={page}&expansionCodes={expansion}"
        print(f"\nğŸ“„ æŠ“å–åˆ—è¡¨é  page {page}")

        ids = get_card_ids(list_url)
        if not ids:
            print("âš  æ²’æœ‰æ›´å¤šå¡ç‰Œï¼Œåœæ­¢")
            break

        for cid in ids:
            detail = get_card_detail(cid, expansion)

            print(
                detail["card_id"], 
                detail["name"], 
                detail["hp"], 
                detail["stage"],
                detail["image_url"],
                detail["info"], 
                detail["energy_en"],
                detail["collection_code"],
                detail["specal_card_type"],
                detail["rarity_id"]
            )

            cards.append(detail)

        page += 1

    save_to_json(cards)